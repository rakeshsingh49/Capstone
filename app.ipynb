{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./opt/anaconda3/lib/python3.8/site-packages (3.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: click<8.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (7.1.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.0.0)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp38-cp38-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.0 MB 8.3 MB/s eta 0:00:011     |███████████████████████████▋    | 20.8 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.17.0 in ./opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in ./opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in ./opt/anaconda3/lib/python3.8/site-packages (from gensim) (5.0.0)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.0.0\n",
      "    Uninstalling gensim-4.0.0:\n",
      "      Successfully uninstalled gensim-4.0.0\n",
      "Successfully installed gensim-4.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from flask) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neuralcoref\n",
      "  Downloading neuralcoref-4.0.tar.gz (368 kB)\n",
      "\u001b[K     |████████████████████████████████| 368 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from neuralcoref) (1.19.2)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.22.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from neuralcoref) (2.27.1)\n",
      "Requirement already satisfied: spacy>=2.1.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from neuralcoref) (3.2.4)\n",
      "Collecting botocore<1.26.0,>=1.25.0\n",
      "  Downloading botocore-1.25.0-py3-none-any.whl (8.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.7 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 3.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (0.7.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (20.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (8.0.15)\n",
      "Requirement already satisfied: setuptools in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (50.3.1.post20201107)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (2.4.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (4.50.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (2.11.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (1.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (0.9.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (3.0.9)\n",
      "Requirement already satisfied: click<8.1.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (7.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy>=2.1.0->neuralcoref) (0.6.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.26.0,>=1.25.0->boto3->neuralcoref) (2.8.1)\n",
      "Requirement already satisfied: six in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy>=2.1.0->neuralcoref) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy>=2.1.0->neuralcoref) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=2.1.0->neuralcoref) (3.7.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy>=2.1.0->neuralcoref) (1.1.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy>=2.1.0->neuralcoref) (5.0.0)\n",
      "Building wheels for collected packages: neuralcoref\n",
      "  Building wheel for neuralcoref (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neuralcoref: filename=neuralcoref-4.0-cp38-cp38-macosx_10_9_x86_64.whl size=281302 sha256=27edb69e95b7424c9600427f94da45df6a405608faee2106472bb4ba9b4c1950\n",
      "  Stored in directory: /Users/rakeshmac/Library/Caches/pip/wheels/2c/0b/d4/be6e85f480e2a238aaa98182f52eb6fc410c25b705ffb3b1e9\n",
      "Successfully built neuralcoref\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, neuralcoref\n",
      "Successfully installed boto3-1.22.0 botocore-1.25.0 jmespath-1.0.0 neuralcoref-4.0 s3transfer-0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug:127.0.0.1 - - [01/May/2022 22:53:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/May/2022 22:53:58] \"\u001b[37mGET /static/css/whatsapp-image-2022-04-08-at-3-55-1@2x.png HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/May/2022 22:53:58] \"\u001b[36mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/May/2022 22:53:58] \"\u001b[33mGET /head.png HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/May/2022 22:53:58] \"\u001b[37mGET /static/css/Background.png HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/May/2022 22:53:58] \"\u001b[33mGET /static/css/LEMONMILK-Bold.otf HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, url_for, render_template, request\n",
    "import spacy\n",
    "from summarizer import Summarizer\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#from urllib import urlopen\n",
    "from urllib.request import urlopen\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from newspaper import Article\n",
    "import newspaper\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "#file name = summarizer-frame\n",
    "\n",
    "\n",
    "@app.route('/analyze', methods=['GET', 'POST'])\n",
    "def analyze():\n",
    "    if request.method == 'POST':\n",
    "        rawtext = request.form['rawtext']\n",
    "        #SUMMARIZATION\n",
    "        #final_summary = text_summarizer(rawtext)\n",
    "    #return render_template('index.html', final_summary)\n",
    "    \n",
    "        model = Summarizer()\n",
    "        result = model(rawtext)\n",
    "        final_summary = ''.join(result)\n",
    "    #sys.path.append(os.path.join(os.path.abspath(os.getcwd()), \"index.html\"))\n",
    "    #os.chdir('/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/')\n",
    "    print(final_summary)\n",
    "    return render_template('index.html', summary=final_summary)\n",
    "'''\n",
    "#GET DATA FROM URL\n",
    "def get_text(url):\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    fetched_text = \" \".join(map(lambda p: p.text.soup.find_all('p')))\n",
    "    print(\"hello world\")\n",
    "    return fetched_text\n",
    "\n",
    "@app.route('/analyze', methods=['GET', 'POST'])\n",
    "def analyze_url():\n",
    "    if request.method == 'POST':\n",
    "        raw_url = request.form['raw_url']\n",
    "        rawtext = get_text(raw_url)\n",
    "        \n",
    "        #SUMMARIZATION\n",
    "        #final_summary = text_summarizizer(rawtext)\n",
    "        model = Summarizer()\n",
    "        result = model(rawtext)\n",
    "        final_summary = ''.join(result)\n",
    "        #print(final_summary)\n",
    "    return render_template('index.html', final_summary)\n",
    "'''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-extractive-summarizer==0.4.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (0.4.2)\n",
      "Requirement already satisfied: spacy in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from bert-extractive-summarizer==0.4.2) (3.2.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from bert-extractive-summarizer==0.4.2) (0.23.2)\n",
      "Requirement already satisfied: transformers in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from bert-extractive-summarizer==0.4.2) (4.18.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (8.0.15)\n",
      "Requirement already satisfied: setuptools in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (50.3.1.post20201107)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (0.7.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (2.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (4.50.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (2.11.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (2.27.1)\n",
      "Requirement already satisfied: click<8.1.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (7.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (20.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (0.6.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (1.19.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (3.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from spacy->bert-extractive-summarizer==0.4.2) (0.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer==0.4.2) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer==0.4.2) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->bert-extractive-summarizer==0.4.2) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer==0.4.2) (2020.10.15)\n",
      "Requirement already satisfied: filelock in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer==0.4.2) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer==0.4.2) (0.0.49)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer==0.4.2) (0.5.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer==0.4.2) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from transformers->bert-extractive-summarizer==0.4.2) (5.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy->bert-extractive-summarizer==0.4.2) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer==0.4.2) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer==0.4.2) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer==0.4.2) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer==0.4.2) (2.10)\n",
      "Requirement already satisfied: six in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy->bert-extractive-summarizer==0.4.2) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy->bert-extractive-summarizer==0.4.2) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy->bert-extractive-summarizer==0.4.2) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy->bert-extractive-summarizer==0.4.2) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-extractive-summarizer==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (0.2.8)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (6.0.8)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (4.6.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (8.0.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (3.2.1)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (2.8.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (4.9.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (3.5)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (5.3.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from newspaper3k) (2.27.1)\n",
      "Requirement already satisfied: sgmllib3k in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: six in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
      "Requirement already satisfied: idna in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from tldextract>=2.0.1->newspaper3k) (2.10)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.0.1)\n",
      "Requirement already satisfied: click in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (0.17.0)\n",
      "Requirement already satisfied: tqdm in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (4.50.2)\n",
      "Requirement already satisfied: regex in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from nltk>=3.2.1->newspaper3k) (2020.10.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.10.0->newspaper3k) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k\n",
    "from newspaper import Article\n",
    "import newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import nltk\n",
    "import requests\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are using request package to make a GET request for the website, which means we're getting data from it.\n",
    "#r=requests.get('https://www.newsy.com/stories/commercial-companies-advance-space-exploration/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article('http://127.0.0.1:5000/')\n",
    "\n",
    "#https://www.nature.com/articles/s41746-019-0155-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rakeshmac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "article.parse()\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As the UK sits in painful deadlock over Brexit, it is important to remember that governments are regularly faced with crises, and their responses can create enduring benefit for future generations. Back in 1858, for example, the UK parliament was dealing with another messy crisis: “the great stink.” In a world before sanitation, the river Thames had become an open latrine, and as summer blossomed parliament was engulfed in a pestilential stench. £2.5 million (about £300 million in today’s money) was hastily approved to build a network of sewers throughout the capital.1 This particular model of sanitation, developed by Bazalgette, was adopted by other cities around the world and the rest, as they say, is history. It is now unthinkable that a developed nation would not have sanitation infrastructure. However, back in 1858 the debate was whether sanitation infrastructure was worthy of investment and whether it was a public or private good. A similar debate has been simmering for some time regarding health data infrastructure, defined as the hardware and software to securely aggregate, store, process and transmit healthcare data. Is data infrastructure necessary for healthcare organizations and if so, is it the responsibility of individual healthcare organizations, of local health systems, or is it a public good?\\n\\nIn the 21st Century, the age of big data and artificial intelligence (AI), each healthcare organization has built its own data infrastructure to support its own needs, typically involving on-premises computing and storage.2,3 Data is balkanized along organizational boundaries, severely constraining the ability to provide services to patients across a care continuum within one organization or across organizations. This situation evolved as individual organizations had to buy and maintain the costly hardware and software required for healthcare, and has been reinforced by vendor lock-in, most notably in electronic medical records (EMRs). With increasing cost pressure and policy imperatives to manage patients across and between care episodes, the need to aggregate data across and between departments within a healthcare organization and across disparate organizations has become apparent not only to realize the promise of AI but also to improve the efficiency of existing data intensive tasks such as any population level segmentation4 and patient safety monitoring.5\\n\\nThe rapid explosion in AI has introduced the possibility of using aggregated healthcare data to produce powerful models that can automate diagnosis6 and also enable an increasingly precision approach to medicine by tailoring treatments and targeting resources with maximum effectiveness in a timely and dynamic manner.7,8\\n\\nHowever, “the inconvenient truth” is that at present the algorithms that feature prominently in research literature are in fact not, for the most part, executable at the frontlines of clinical practice. This is for two reasons: first, these AI innovations by themselves do not re-engineer the incentives that support existing ways of working.2 A complex web of ingrained political and economic factors as well as the proximal influence of medical practice norms and commercial interests determine the way healthcare is delivered. Simply adding AI applications to a fragmented system will not create sustainable change. Second, most healthcare organizations lack the data infrastructure required to collect the data needed to optimally train algorithms to (a) “fit” the local population and/or the local practice patterns, a requirement prior to deployment that is rarely highlighted by current AI publications, and (b) interrogate them for bias to guarantee that the algorithms perform consistently across patient cohorts, especially those who may not have been adequately represented in the training cohort.9 For example, an algorithm trained on mostly Caucasian patients is not expected to have the same accuracy when applied to minorities.10 In addition, such rigorous evaluation and re-calibration must continue after implementation to track and capture those patient demographics and practice patterns which inevitably change over time.11 Some of these issues can be addressed through external validation, the importance of which is not unique to AI, and it is timely that existing standards for prediction model reporting are being updated specifically to incorporate standards applicable to this end.12 In the United States, there are islands of aggregated healthcare data in the ICU,13 and in the Veterans Administration.14 These aggregated data sets have predictably catalyzed an acceleration in AI development; but without broader development of data infrastructure outside these islands it will not be possible to generalize these innovations.\\n\\nElsewhere in the economy, the development of cloud computing, secure high-performance general use data infrastructure and services available via the Internet (the “cloud”), has been a significant enabler for large and small technology companies alike, providing significantly lower fixed costs and higher performance as well as supporting the aforementioned opportunities for AI. Healthcare, with its abundance of data, is in theory well-poised to benefit from growth in cloud computing. The largest and arguably most valuable store of data in healthcare rests in EMRs. However, clinician satisfaction with EMRs remains low, resulting in variable completeness and quality of data entry, and interoperability between different providers remains elusive.11 The typical lament of a harried clinician is still “why does my EMR still suck and why don’t all these systems just talk to each other?” Policy imperatives have attempted to address these dilemmas, however progress has been minimal. In spite of the widely touted benefits of “data liberation”,15 a sufficiently compelling use case has not been presented to overcome the vested interests maintaining the status quo and justify the significant upfront investment necessary to build data infrastructure. Furthermore, it is reasonable to suggest that such high-performance computing work has been and continues to be beyond the core competencies of either healthcare organizations or governments16 and as such, policies have been formulated, but rarely, if ever, successfully implemented. It is now time to revisit these policy imperatives in light of the availability of secure, scalable data infrastructure available through cloud computing that makes the vision of interoperability realizable, at least in theory.\\n\\nTo realize this vision and to realize the potential of AI across health systems, more fundamental issues have to be addressed: who owns health data, who is responsible for it, and who can use it? Cloud computing alone will not answer these questions—public discourse and policy intervention will be needed. The specific path forward will depend on the degree of a social compact around healthcare itself as a public good, the tolerance to public private partnership, and crucially, the public’s trust in both governments and the private sector to treat their healthcare data with due care and attention in the face of both commercial and political perverse incentives.\\n\\nIn terms of the private sector these concerns are amplified as cloud computing is provided by a small number of large technology companies who have both significant market power and strong commercial interests outside of healthcare for which healthcare data might potentially be beneficial. Specific contracting instruments are needed to ensure that data sharing involves both necessary protection as well as, where relevant, fair material returns to healthcare organizations and the patients they serve.17 In the absence of a general approach to contracting, high profile cases in this area have been corrosive to public trust.18,19 Data privacy regulations like the European Union’s General Data Protection Regulation20 (GDPR) or California’s Consumer Privacy Act21 are necessary and well intentioned, though incur the risk of favoring well-resourced incumbents who are more able to meet the cost of regulatory compliance thereby possibly limiting the growth of smaller healthcare provider and technology organizations. Initiatives to give patients access to their healthcare data, including new proposals from the Center for Medicare and Medicaid Services22 are welcome, and in fact it has long been argued that patients themselves should be the owners and guardians of their health data and subsequently consent to their data being used to develop AI solutions.16 In this scenario, as in the current scenario where healthcare organizations are the de-facto owners and guardians of patient data generated in the health system alongside fledgling initiatives from prominent technology companies to share patient generated data back into the health system,23 there exists the need for secure, high-performance data infrastructure to make use of this data for AI applications.\\n\\nIf the aforementioned issues are addressed, there are two possible routes to building the necessary data infrastructure to enable today’s clinical care and population health management and tomorrow’s AI enabled workflows. The first is an evolutionary path to creating generalized data infrastructure by building on existing impactful successes in the research domain such as the recent Science and Technology Research Infrastructure for Discovery, Experimentation and Sustainability (STRIDES) initiative from the National Institutes of Health24 or MIMIC from the MIT Laboratory for Computational Physiology13 to generate the momentum for change. Another, more revolutionary path would be for governments to mandate that all healthcare organizations store their clinical data in commercially available clouds. In either scenario, existing initiatives such as the Observational Medical Outcomes Partnership (OMOP25) and Fast Healthcare Interoperability Resources (FHIR) standard26 that create a common data schema for storage and transfer of healthcare data as well as AI enabled technology innovations to accelerate the migration of existing data27 will accelerate progress and ensure that legacy data are included. There are several complex problems still to be solved including how to enable informed consent for data sharing, and how to protect confidentiality yet maintain data fidelity. However, the prevalent scenario for data infrastructure development will depend more on the socio-economic context of the health system in question rather than on technology.\\n\\nA notable by-product of a move of clinical as well as research data to the cloud would be the erosion of market power of EMR providers. The status quo with proprietary data formats and local hosting of EMR databases favors incumbents who have strong financial incentives to maintain the status quo. Creation of health data infrastructure opens the door for innovation and competition within the private sector to fulfill the public aim of interoperable health data.\\n\\nThe potential of AI is well described, however in reality health systems are faced with a choice: to significantly downgrade the enthusiasm regarding the potential of AI in everyday clinical practice, or to resolve issues of data ownership and trust and invest in the data infrastructure to realize it. Now that the growth of cloud computing in the broader economy has bridged the computing gap, the opportunity exists to both transform population health and realize the potential of AI, if governments are willing to foster a productive resolution to issues of ownership of healthcare data through a process that necessarily transcends election cycles and overcomes or co-opts the vested interests that maintain the status quo—a tall order. Without this however, opportunities for AI in healthcare will remain just that—opportunities.\\n\\nReferences OpenLearn, The Open University. How London got its Victorian sewers. https://www.open.edu/openlearn/science-maths-technology/engineering-technology/how-london-got-its-victorian-sewers (2018). Rajkomar, A., Dean, J. & Kohane, I. Machine learning in medicine. N. Eng. J. Med. 380, 1347–1358 (2019). Panch, T., Szolovits, P. & Atun, R. Artificial intelligence, machine learning and health systems. J. Glob. Health 8, 020303 (2018). Yan, S. et al. A systematic review of the clinical application of data-driven population segmentation analysis. BMC Med. Res. Methodol. 18, 121 (2018). Pronovost, P. J. et al. Paying the Piper: investing in infrastructure for patient safety. Jt Comm. J. Qual. Patient Saf. 34, 342–348 (2008). Keane, P. A. & Topol, E. J. With an eye to AI and autonomous diagnosis. NPJ Digit Med 1, 40 (2018). Shaban-Nejad, A., Michalowski, M. & Buckeridge, D. Health intelligence: how artificial intelligence transforms population and personalized health. NPJ Digit Med. 1, 53 (2018). Fogel, A. L. & Kvedar, J. C. Artificial intelligence powers digital medicine. NPJ Digit Med. 1, 5 (2018). Gijsberts, C. M. et al. Race/ethnic differences in the associations of the framingham risk factors with carotid IMT and cardiovascular events. PLoS ONE 10, e0132321 (2015). Hermansson, J. & Kahan, T. Systematic review of validity assessments of Framingham risk scoreresults in health economic modelling of lipid-modifying therapies in Europe. Pharmacoeconomics 36, 205–213 (2017). Fry, E., Schulte, F. Death by a thousand clicks: where electronic health records went wrong. https://www.fortune.com/longform/medical-records (2019). Collins, G. S. & Moons, K. G. M. Reporting of artificial intelligence prediction models. Lancet 393, 1577–1579 (2019). Johnson, A. E. W. et al. MIMIC-III, a freely accessible critical care database. Sci. Data. 3, 160035 (2016). U.S. Department of Veterans Affairs. VA Informatics and Computing Infrastructure. https://www.hsrd.research.va.gov/for_researchers/vinci/cdw.cfm (2014). Park, T., Sivak, B. Health Datapalooza IV Tops Off a Huge Year in Health Data Liberation & Innovation. https://obamawhitehouse.archives.gov/blog/2013/06/07/health-datapalooza-iv-tops-huge-year-health-data-liberation-innovation (2013). Mandl, K. D., Szolovits, P. & Kohane, I. Public standards and patients’ control: how to keep electronic medical records accessible but private. BMJ 322, 283–287 (2001). Panch, T. et al. Artificial intelligence: opportunities and risks for public health. Lancet Digit Health 1, e13–e14 (2019). Ornstein, C., Thomas, K. Sloan Kettering’s cozy deal with start-up ignites a new uproar. https://www.nytimes.com/2018/09/20/health/memorial-sloan-kettering-cancer-paige-ai.html (2018). Revell, T. Google DeepMind’s NHS data deal ‘failed to comply’ with law. https://www.newscientist.com/article/2139395-google-deepminds-nhs-data-deal-failed-to-comply-with-law/ (2017). European Parliament, Council of the European Union. Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (Text with EEA relevance). https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX:32016R0679 (2016). California Legislative Information. AB-375 Privacy: personal information: businesses. https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180AB375 (2018). Centers for Medicare & Medicaid Services. CMS Advances Interoperability & Patient Access to Health Data through New Proposals. https://www.cms.gov/newsroom/fact-sheets/cms-advances-interoperability-patient-access-health-data-through-new-proposals (2019). Apple Newsroom. Apple announces effortless solution bringing health records to iPhone. https://www.apple.com/newsroom/2018/01/apple-announces-effortless-solution-bringing-health-records-to-iPhone/ (2018). National Institutes of Health. STRIDES. https://datascience.nih.gov/strides (2019). Observational Health Data Sciences and Informatics. OMOP Common Data Model. https://www.ohdsi.org/data-standardization/the-common-data-model/ (2019). HL7. Introducing HL7 FHIR. https://www.hl7.org/fhir/summary.html (2018). Rajkomar, A. et al. Scalable and accurate deep learning with electronic health records. NPJ Digit Med. 1, 18 (2018). Download references\\n\\nAcknowledgements L.A.C. is funded by the National Institute of Health through the NIBIB grant R01 EV017205.\\n\\nAuthor information Affiliations Division of Health Policy and Management, Harvard T.H. Chan School of Public Health, Boston, MA, USA Trishan Panch Wellframe Inc., Boston, MA, USA Trishan Panch & Heather Mattie Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA, USA Heather Mattie Institute for Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, MA, USA Leo Anthony Celi Division of Pulmonary, Critical Care and Sleep Medicine, Beth Israel Deaconess Medical Center, Boston, MA, USA Leo Anthony Celi Authors Trishan Panch View author publications You can also search for this author in PubMed Google Scholar Heather Mattie View author publications You can also search for this author in PubMed Google Scholar Leo Anthony Celi View author publications You can also search for this author in PubMed Google Scholar Contributions T.P. wrote the first draft. All authors contributed to both the subsequent drafting and critical revision of the manuscript. Corresponding author Correspondence to Leo Anthony Celi.\\n\\nEthics declarations Competing interests The authors declare no competing interests.\\n\\nAdditional information Publisher’s note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n\\nRights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/. Reprints and Permissions'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A similar debate has been simmering for some time regarding health data infrastructure, defined as the hardware and software to securely aggregate, store, process and transmit healthcare data.\n",
      "Is data infrastructure necessary for healthcare organizations and if so, is it the responsibility of individual healthcare organizations, of local health systems, or is it a public good?\n",
      "Another, more revolutionary path would be for governments to mandate that all healthcare organizations store their clinical data in commercially available clouds.\n",
      "Creation of health data infrastructure opens the door for innovation and competition within the private sector to fulfill the public aim of interoperable health data.\n",
      "Chan School of Public Health, Boston, MA, USA Trishan Panch Wellframe Inc., Boston, MA, USA Trishan Panch & Heather Mattie Department of Biostatistics, Harvard T.H.\n"
     ]
    }
   ],
   "source": [
    "print(article.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:17:32] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:17:33] \"\u001b[33mGET /head.png HTTP/1.1\u001b[0m\" 404 -\n",
      "loading configuration file https://huggingface.co/bert-large-uncased/resolve/main/config.json from cache at /Users/rakeshmac/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-large-uncased/resolve/main/pytorch_model.bin from cache at /Users/rakeshmac/.cache/huggingface/transformers/1d959166dd7e047e57ea1b2d9b7b9669938a7e90c5e37a03961ad9f15eaea17f.fea64cd906e3766b04c92397f9ad3ff45271749cbe49829a079dd84e34c1697d\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file https://huggingface.co/bert-large-uncased/resolve/main/vocab.txt from cache at /Users/rakeshmac/.cache/huggingface/transformers/e12f02d630da91a0982ce6db1ad595231d155a2b725ab106971898276d842ecc.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-large-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-large-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-large-uncased/resolve/main/tokenizer_config.json from cache at /Users/rakeshmac/.cache/huggingface/transformers/300ecd79785b4602752c0085f8a89c3f0232ef367eda291c79a5600f3778b677.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-large-uncased/resolve/main/config.json from cache at /Users/rakeshmac/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:18:02] \"\u001b[35m\u001b[1mPOST /analyze HTTP/1.1\u001b[0m\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 2464, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 2450, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 1867, in handle_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-8-c1f1c0265637>\", line 33, in analyze\n",
      "    \n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/model_processors.py\", line 116, in __call__\n",
      "    return self.run(body, ratio, min_length, max_length, algorithm=algorithm, use_first=use_first)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/model_processors.py\", line 90, in run\n",
      "    sentences = self.run_clusters(sentences, ratio, algorithm, use_first)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/model_processors.py\", line 141, in run_clusters\n",
      "    hidden = self.model(content, self.hidden, self.reduce_option)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/bert_parent.py\", line 125, in __call__\n",
      "    return self.create_matrix(content, hidden, reduce_option)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/bert_parent.py\", line 114, in create_matrix\n",
      "    return np.asarray([\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/bert_parent.py\", line 115, in <listcomp>\n",
      "    np.squeeze(self.extract_embeddings(t, hidden=hidden, reduce_option=reduce_option).data.cpu().numpy())\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/summarizer/bert_parent.py\", line 84, in extract_embeddings\n",
      "    pooled, hidden_states = self.model(tokens_tensor)[-2:]\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 989, in forward\n",
      "    embedding_output = self.embeddings(\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 214, in forward\n",
      "    inputs_embeds = self.word_embeddings(input_ids)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/sparse.py\", line 158, in forward\n",
      "    return F.embedding(\n",
      "  File \"/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 2183, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:18:04] \"\u001b[37mGET /analyze?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:18:04] \"\u001b[37mGET /analyze?__debugger__=yes&cmd=resource&f=jquery.js HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:18:04] \"\u001b[37mGET /analyze?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:18:04] \"\u001b[37mGET /analyze?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [25/Apr/2022 22:18:04] \"\u001b[37mGET /analyze?__debugger__=yes&cmd=resource&f=ubuntu.ttf HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Second Edition ######\n",
    "\n",
    "from flask import Flask, url_for, render_template, request\n",
    "\n",
    "import spacy\n",
    "from summarizer import Summarizer\n",
    "#nlp = spacy.load('en')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "#from urllib import urlopen\n",
    "from urllib.request import urlopen\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "#file name = summarizer-frame\n",
    "\n",
    "\n",
    "@app.route('/analyze', methods=['GET', 'POST'])\n",
    "def analyze():\n",
    "    if request.method == 'POST':\n",
    "        rawtext = request.form['rawtext']\n",
    "        #SUMMARIZATION\n",
    "        #final_summary = text_summarizer(rawtext)\n",
    "    #return render_template('index.html', final_summary)\n",
    "    \n",
    "        model = Summarizer()\n",
    "        result = model(rawtext)\n",
    "        final_summary = ''.join(result)\n",
    "        print(final_summary)\n",
    "    #sys.path.append(os.path.join(os.path.abspath(os.getcwd()), \"index.html\"))\n",
    "    #os.chdir('/Users/rakeshmac/opt/anaconda3/lib/python3.8/site-packages/flask/')\n",
    "    return render_template('index.html', final_summary)\n",
    "\n",
    "#GET DATA FROM URL\n",
    "def get_text(url):\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    fetched_text = \" \".join(map(lambda p: p.text.soup.find_all('p')))\n",
    "    return fetched_text\n",
    "\n",
    "@app.route('/analyze', methods=['GET', 'POST'])\n",
    "def analyze_url():\n",
    "    if request.method == 'POST':\n",
    "        raw_url = request.form['raw_url']\n",
    "        rawtext = get_text(raw_url)\n",
    "        \n",
    "        #SUMMARIZATION\n",
    "        #final_summary = text_summarizizer(rawtext)\n",
    "        model = Summarizer()\n",
    "        result = model(rawtext)\n",
    "        final_summary = ''.join(result)\n",
    "        print(final_summary)\n",
    "    return render_template('index.html', final_summary)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rakeshmac/Text Sum'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rakeshmac/Text Sum\n"
     ]
    }
   ],
   "source": [
    "cd /Users/rakeshmac/Text Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rakeshmac/ernie/Ernie-master 2\n"
     ]
    }
   ],
   "source": [
    "cd Ernie-master 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"app.py\", line 2, in <module>\r\n",
      "    from spacy_summarization import text_summarizer\r\n",
      "ModuleNotFoundError: No module named 'spacy_summarization'\r\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement spacy_summarization (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for spacy_summarization\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy_summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
